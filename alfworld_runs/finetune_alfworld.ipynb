{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdaf1346-cff8-4c48-94be-e4e8649e9d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "\n",
    "trial = \"baselines/react_train_all\"\n",
    "\n",
    "# Configuration: adjust these paths as needed\n",
    "METADATA_CSV = f\"game_logs/{trial}/alfworld_results.csv\"\n",
    "PROMPT_BASE_DIR = f\"game_logs/{trial}/\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # Something to include to fix unsloth on jupyter\n",
    "os.environ[\"TRITON_DISABLE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f039225d-51a8-4765-8b45-6e64b1ef43fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # --- config you can tweak ---\n",
    "# CSV_PATH   = f\"game_logs/{trial}/alfworld_results.csv\"\n",
    "# DATA_ROOT  = \"/workspace/data/alfworld/json_2.1.1\"\n",
    "# SPLITS     = [\"train\", \"valid_seen\", \"valid_unseen\"]\n",
    "# TOPK       = 50\n",
    "\n",
    "# # weights for a simple, nav-free difficulty score\n",
    "# W = {\n",
    "#     \"pickup\": 1.0,\n",
    "#     \"put\": 1.0,\n",
    "#     \"open\": 0.6,\n",
    "#     \"close\": 0.6,\n",
    "#     \"toggle\": 1.2,     # faucets, stove, microwave, lamps…\n",
    "#     \"slice\": 1.2,\n",
    "#     \"use\": 1.0,\n",
    "#     \"uniq_objects\": 1.2,\n",
    "#     \"uniq_recepts\": 1.0,\n",
    "#     \"high_pddl_len\": 1.0,\n",
    "# }\n",
    "\n",
    "# # -------------------------------------------------------------\n",
    "# import json, pandas as pd\n",
    "# from pathlib import Path\n",
    "# from collections import defaultdict\n",
    "\n",
    "# NAV_ACTIONS = {\"MoveAhead\",\"RotateLeft\",\"RotateRight\",\"LookUp\",\"LookDown\",\n",
    "#                \"MoveBack\",\"MoveRight\",\"MoveLeft\"}\n",
    "\n",
    "# API2CAT = {\n",
    "#     \"PickupObject\":  \"pickup\",\n",
    "#     \"PutObject\":     \"put\",\n",
    "#     \"OpenObject\":    \"open\",\n",
    "#     \"CloseObject\":   \"close\",\n",
    "#     \"ToggleObjectOn\":  \"toggle\",\n",
    "#     \"ToggleObjectOff\": \"toggle\",\n",
    "#     \"SliceObject\":   \"slice\",\n",
    "#     \"UseObject\":     \"use\",  # occasionally present\n",
    "# }\n",
    "\n",
    "# def resolve_traj(env_ref: str, data_root: Path, splits: list[str]) -> Path | None:\n",
    "#     \"\"\"\n",
    "#     env_ref like: 'pick_cool_then_place_in_recep-.../trial_T2019...'\n",
    "#     Returns the path to traj_data.json, or None.\n",
    "#     \"\"\"\n",
    "#     p = data_root / env_ref\n",
    "#     if p.is_dir() and (p / \"traj_data.json\").is_file():\n",
    "#         return p / \"traj_data.json\"\n",
    "#     if p.name == \"traj_data.json\" and p.is_file():\n",
    "#         return p\n",
    "#     if p.name == \"game.tw-pddl\" and p.with_name(\"traj_data.json\").is_file():\n",
    "#         return p.with_name(\"traj_data.json\")\n",
    "#     for sp in splits:\n",
    "#         base = data_root / sp / env_ref\n",
    "#         if base.is_dir() and (base / \"traj_data.json\").is_file():\n",
    "#             return base / \"traj_data.json\"\n",
    "#         if base.name == \"traj_data.json\" and base.is_file():\n",
    "#             return base\n",
    "#         if base.name == \"game.tw-pddl\" and base.with_name(\"traj_data.json\").is_file():\n",
    "#             return base.with_name(\"traj_data.json\")\n",
    "#     return None\n",
    "\n",
    "# def difficulty_non_nav(traj_json: dict) -> dict:\n",
    "#     \"\"\"Compute nav-free difficulty signals from traj_data.json dict.\"\"\"\n",
    "#     low = traj_json[\"plan\"][\"low_actions\"]\n",
    "#     hi  = traj_json[\"plan\"].get(\"high_pddl\", [])\n",
    "\n",
    "#     counts = defaultdict(int)\n",
    "#     uniq_objs    = set()\n",
    "#     uniq_recepts = set()\n",
    "\n",
    "#     for step in low:\n",
    "#         api = (step.get(\"api_action\") or {})\n",
    "#         a = api.get(\"action\", \"\")\n",
    "#         if a in NAV_ACTIONS:\n",
    "#             continue  # drop pure nav\n",
    "\n",
    "#         # map to interaction category (fallback to name if unknown)\n",
    "#         cat = API2CAT.get(a)\n",
    "#         if cat:\n",
    "#             counts[cat] += 1\n",
    "\n",
    "#         # track objects touched\n",
    "#         oid = api.get(\"objectId\")\n",
    "#         rid = api.get(\"receptacleObjectId\")\n",
    "#         if oid: uniq_objs.add(oid)\n",
    "#         if rid: uniq_recepts.add(rid)\n",
    "\n",
    "#     # high-level (subgoal) count\n",
    "#     high_len = len(hi)\n",
    "    \n",
    "#     # build score (tweak W as needed)\n",
    "#     score = (\n",
    "#         W[\"pickup\"] * counts[\"pickup\"] +\n",
    "#         W[\"put\"]    * counts[\"put\"] +\n",
    "#         W[\"open\"]   * counts[\"open\"] +\n",
    "#         W[\"close\"]  * counts[\"close\"] +\n",
    "#         W[\"toggle\"] * counts[\"toggle\"] +\n",
    "#         W[\"slice\"]  * counts[\"slice\"] +\n",
    "#         W[\"use\"]    * counts[\"use\"] +\n",
    "#         W[\"uniq_objects\"] * len(uniq_objs) +\n",
    "#         W[\"uniq_recepts\"] * len(uniq_recepts) +\n",
    "#         W[\"high_pddl_len\"] * high_len\n",
    "#     )\n",
    "\n",
    "#     return {\n",
    "#         \"score\": round(float(score), 3),\n",
    "#         \"high_pddl_len\": high_len,\n",
    "#         \"n_pickup\": counts[\"pickup\"],\n",
    "#         \"n_put\": counts[\"put\"],\n",
    "#         \"n_open\": counts[\"open\"],\n",
    "#         \"n_close\": counts[\"close\"],\n",
    "#         \"n_toggle\": counts[\"toggle\"],\n",
    "#         \"n_slice\": counts[\"slice\"],\n",
    "#         \"n_use\": counts[\"use\"],\n",
    "#         \"uniq_objects\": len(uniq_objs),\n",
    "#         \"uniq_recepts\": len(uniq_recepts),\n",
    "#     }\n",
    "\n",
    "# # ---------- run over your CSV and rank top-K per env_type ----------\n",
    "# CSV = pd.read_csv(CSV_PATH)\n",
    "# CSV = CSV[CSV[\"success\"]==True]\n",
    "# env_ref_col = \"env_referencem\" if \"env_referencem\" in CSV.columns else \"env_reference\"\n",
    "# need = [\"env_idx\", \"env_type\", env_ref_col]\n",
    "# CSV = CSV.dropna(subset=need)[need].drop_duplicates(subset=[\"env_idx\"]).reset_index(drop=True)\n",
    "\n",
    "# records = []  # (env_type, score, env_idx, traj_path, metrics_dict)\n",
    "# data_root = Path(DATA_ROOT)\n",
    "# skipped = 0\n",
    "\n",
    "# for _, row in CSV.iterrows():\n",
    "#     env_idx = int(row[\"env_idx\"])\n",
    "#     env_type = str(row[\"env_type\"])\n",
    "#     env_ref = str(row[env_ref_col])\n",
    "#     tpath = resolve_traj(env_ref, data_root, SPLITS)\n",
    "#     if not tpath:\n",
    "#         skipped += 1\n",
    "#         continue\n",
    "#     try:\n",
    "#         with open(tpath) as f:\n",
    "#             tj = json.load(f)\n",
    "#         m = difficulty_non_nav(tj)\n",
    "#         records.append((env_type, m[\"score\"], env_idx, str(tpath), m))\n",
    "#     except Exception:\n",
    "#         skipped += 1\n",
    "\n",
    "# if skipped:\n",
    "#     print(f\"Note: skipped {skipped} unresolved/invalid trajectories.\")\n",
    "\n",
    "# # group and pick top-K\n",
    "# by_type = defaultdict(list)\n",
    "# for env_type, score, eidx, pth, m in records:\n",
    "#     by_type[env_type].append((score, eidx, pth, m))\n",
    "\n",
    "# topk_by_type = {}\n",
    "# env_hardness = {}\n",
    "# print(f\"\\nTop-{TOPK} hardest (nav-free) by env_type:\\n\")\n",
    "# for t in sorted(by_type):\n",
    "#     # tie-breaker: smaller env_idx first\n",
    "#     topk = sorted(by_type[t], key=lambda x: (-x[0], x[1]))[:TOPK]\n",
    "#     topk_by_type[t] = [eidx for score, eidx, _, _ in topk]\n",
    "#     env_hardness.update({eidx:score for score, eidx, _, _ in topk})\n",
    "#     print(f\"[{t}]\")\n",
    "#     for rank, (score, eidx, pth, m) in enumerate(topk, 1):\n",
    "#         print(f\"  #{rank}  score={score:<6} env_idx={eidx:<5}  {pth}  \"\n",
    "#               f\"(hi={m['high_pddl_len']}, pick={m['n_pickup']}, put={m['n_put']}, \"\n",
    "#               f\"open={m['n_open']}, close={m['n_close']}, tog={m['n_toggle']}, \"\n",
    "#               f\"obj={m['uniq_objects']}, rec={m['uniq_recepts']})\")\n",
    "#     print()\n",
    "\n",
    "# print(\"env_idx lists:\")\n",
    "# for t in sorted(topk_by_type):\n",
    "#     print(f'  {t:>8}: {topk_by_type[t]}')\n",
    "\n",
    "# env_indices = []\n",
    "# for key, value in topk_by_type.items():\n",
    "#     print(key, value)\n",
    "#     env_indices.extend(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8af90a1f-accf-45a6-a388-ac3b6fa9037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def peek_plan(traj_path):\n",
    "#     j = json.load(open(traj_path))\n",
    "#     plan = j.get(\"plan\", {})\n",
    "#     keys = list(plan.keys())\n",
    "#     print(\"keys:\", keys)\n",
    "#     print(\"high_pddl len:\", len(plan.get(\"high_pddl\", [])))\n",
    "#     print(\"high_actions len:\", len(plan.get(\"high_actions\", [])))\n",
    "#     print(\"high_descs len:\", len(plan.get(\"high_descs\", [])))\n",
    "#     print(\"low_actions len:\", len(plan.get(\"low_actions\", [])))\n",
    "#     # optionally show a few items\n",
    "#     print(\"sample high_actions:\", plan.get(\"high_actions\", [])[:5])\n",
    "#     print(\"sample low_actions:\", plan.get(\"low_actions\", [])[:5])\n",
    "\n",
    "# # Check experiment details\n",
    "# traj = pathlib.Path(\"/rds/general/user/hai24/home/.cache/alfworld/json_2.1.1/train/pick_two_obj_and_place-CellPhone-None-SideTable-310/trial_T20190908_123211_754215/traj_data.json\")\n",
    "# peek_plan(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85550dd9-e7c0-40ab-8140-60db1ed6e8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from pathlib import Path\n",
    "\n",
    "# def print_high_plan(traj_path: str | Path):\n",
    "#     p = Path(traj_path)\n",
    "#     j = json.load(open(p))\n",
    "#     plan = j.get(\"plan\", {})\n",
    "\n",
    "#     # Prefer high_pddl, fallback to high_actions\n",
    "#     high = plan.get(\"high_pddl\")\n",
    "#     if high is None:\n",
    "#         high = plan.get(\"high_actions\")\n",
    "\n",
    "#     if not high:\n",
    "#         print(f\"No high-level plan found in {p}\")\n",
    "#         print(\"Available keys under plan:\", list(plan.keys()))\n",
    "#         return\n",
    "\n",
    "#     print(f\"\\nHigh-level plan from: {p}\")\n",
    "#     for i, step in enumerate(high, 1):\n",
    "#         if isinstance(step, dict):\n",
    "#             # print(step)\n",
    "#             # common shapes: {\"action\":\"OpenObject\", \"args\":[\"fridge 1\"]} or similar\n",
    "#             act = step.get(\"discrete_action\") or step.get(\"op\") or step.get(\"name\") or \"UNKNOWN\"\n",
    "#             args = step.get(\"args\") or step.get(\"arguments\") or []\n",
    "#             if isinstance(args, (list, tuple)):\n",
    "#                 arg_str = \", \".join(map(str, args))\n",
    "#             else:\n",
    "#                 arg_str = str(args)\n",
    "#             print(f\"{i:02d}. {act}({arg_str})\")\n",
    "#         else:\n",
    "#             # string step\n",
    "#             print(f\"{i:02d}. {step}\")\n",
    "\n",
    "# # Example usage:\n",
    "# print_high_plan(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4daa113-c731-48a8-90c2-37e96c983850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_few_shot_examples(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Keeps the first line ('Interact with a household...') and removes the few-shot examples\n",
    "    between 'Here are 2 examples:' and the last 'Your task is to:'.\n",
    "    \"\"\"\n",
    "    # Extract the first line (system instruction)\n",
    "    first_line, *rest = prompt.split(\"\\n\", 1)\n",
    "    rest_text = rest[0] if rest else \"\"\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    # Split by all occurrences of 'Your task is to:'\n",
    "    parts = rest_text.split(\"Your task is to:\")\n",
    "    if len(parts) < 2:\n",
    "        return prompt  # Nothing to strip\n",
    "\n",
    "    # Keep only the last task and everything that follows\n",
    "    cleaned = first_line.strip() + \"\\n\\nYour task is to:\" + parts[-1]\n",
    "    \n",
    "\n",
    "    #########################################\n",
    "\n",
    "    \n",
    "    # # Split by all occurrences of 'Your task is to:'\n",
    "    # parts = rest_text.split(\"Here is the task\")\n",
    "    # if len(parts) < 2:\n",
    "    #     return prompt  # Nothing to strip\n",
    "\n",
    "    # # Keep only the last task and everything that follows\n",
    "    # cleaned = first_line.strip() + \"\\n\\nHere is the task\" + parts[-1]\n",
    "\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    \n",
    "    # parts = rest_text.split(\"Apply these rules silently to choose the next action.\")\n",
    "    # if len(parts) < 2:\n",
    "    #     return prompt  # Nothing to strip\n",
    "    # cleaned = first_line.strip() + \"\\n\\nHere are some hints\" + parts[-1]\n",
    "\n",
    "    \n",
    "    return cleaned.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70faa15b-f218-443f-813f-bfc1c83bed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_indices = []\n",
    "# for key, value in topk_by_type.items():\n",
    "#     print(key, value)\n",
    "#     env_indices.extend(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "894c3061-8e53-4185-a780-8c29c23f736f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(METADATA_CSV)\n",
    "# df = df[df[\"model\"] == \"Qwen/Qwen2.5-14B-Instruct\"]\n",
    "# df = df[df[\"prompt_name\"] == \"stringstate-1_0-k-goal+locations_visited+current_location+current_inventory+thought+action\"]\n",
    "\n",
    "# print(f\"Average number of steps: {df.num_of_steps.mean()}\")\n",
    "\n",
    "# # ------------------------------------------------------------------\n",
    "# # 4.  Keep *only* those rows whose env_idx is in that list\n",
    "# df = df[df[\"env_idx\"].isin(env_indices)].reset_index(drop=True)\n",
    "# df = df[df[\"success\"] == True].reset_index(drop=True)\n",
    "# df[\"pddl_difficulty\"] = df[\"env_idx\"].map(env_hardness)\n",
    "\n",
    "# def calc_successes(df):\n",
    "#     # Group by env_type\n",
    "#     grouped = df.groupby(\"env_type\")[\"success\"]\n",
    "    \n",
    "#     # Compute success rate and count\n",
    "#     success_stats = grouped.agg(\n",
    "#         success_rate=lambda x: 100 * x.mean(),\n",
    "#         count=\"count\"\n",
    "#     ).round(2)\n",
    "    \n",
    "#     # Print\n",
    "#     print(\"Success Rate and Count by env_type (before filtering):\")\n",
    "#     print(success_stats.to_string())\n",
    "    \n",
    "# def extract_whole_trace(example):\n",
    "#     trace = json.load(open(example[\"trace_file\"]))\n",
    "\n",
    "#     # Prompt = system + initial user\n",
    "#     sys_msg  = next(m[\"content\"] for m in trace if m[\"role\"]==\"system\")\n",
    "#     usr_msg  = next(m[\"content\"] for m in trace if m[\"role\"]==\"user\")\n",
    "\n",
    "#     # print(usr_msg)\n",
    "#     prompt   = sys_msg + \"\\n\" + usr_msg + \"\\n\"\n",
    "#     # Completion = *everything else*, in order\n",
    "#     rest     = trace[2:]\n",
    "#     completion = \"\".join(m[\"content\"] + \"\\n\" for m in rest)\n",
    "#     # add end‐of‐sequence token if needed\n",
    "#     if not completion.endswith(\"\"):\n",
    "#         completion += \"\"\n",
    "        \n",
    "#     match = re.findall(\"Nothing happens.\", completion)\n",
    "#     # if len(match) > 0:\n",
    "#     #     print(len(match))\n",
    "    \n",
    "#     return {\"prompt\": prompt, \"completion\": completion, \"nothing_occ\":len(match)}\n",
    "\n",
    "\n",
    "# print(f\"Kept {len(df)} rows that match the difficult env_idx list.\")\n",
    "# print(df[[\"env_idx\",\"env_type\",\"success\", \"num_of_steps\"]])\n",
    "# df[[\"prompt\", \"completion\", \"nothing_occ\"]] = df.apply(lambda row: pd.Series(extract_whole_trace(row)), axis=1)\n",
    "\n",
    "# removed_examples = len(df[df.nothing_occ != 0])\n",
    "# df = df[df.nothing_occ == 0]\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print(\"\\n\"+\"*\"*50 + f\"\\nTotal removed examples (with nothing happened): {removed_examples}\\n\" + \"*\"*50)\n",
    "\n",
    "# TOPK = 20\n",
    "# # df = df.groupby(\"env_type\", group_keys=False).apply(lambda x: x.sample(TOPK, random_state=42))\n",
    "# df = (\n",
    "#     df.sort_values(['env_type','pddl_difficulty','env_idx'],\n",
    "#                    ascending=[True, False, True])\n",
    "#       .groupby('env_type', group_keys=False)\n",
    "#       .head(TOPK)\n",
    "# )\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# calc_successes(df)\n",
    "\n",
    "# # df = df[[\"prompt\",\"completion\",\"success\",\"total_reward\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "964f8f96-872d-42be-812e-76a47a5a2613",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 32)\n",
      "Success Rate and Count by env_type (before filtering):\n",
      "          success_rate  count\n",
      "env_type                     \n",
      "clean            30.00    220\n",
      "cool             65.80    193\n",
      "examine          84.76    105\n",
      "heat             44.79    163\n",
      "put              87.80    254\n",
      "puttwo           58.87    265\n",
      "\n",
      "**************************************************\n",
      "Total removed examples (with nothing happened): 151\n",
      "**************************************************\n",
      "Success Rate and Count by env_type (before filtering):\n",
      "          success_rate  count\n",
      "env_type                     \n",
      "clean            100.0     58\n",
      "cool             100.0    114\n",
      "examine          100.0     56\n",
      "heat             100.0     63\n",
      "put              100.0    172\n",
      "puttwo           100.0    120\n",
      "\n",
      "**************************************************\n",
      "Final Dataset Size 583\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# This CSV must contain columns 'prompt_file', 'trace_file', and any other metadata fields you care about.\n",
    "df = pd.read_csv(METADATA_CSV)\n",
    "# df = df[df[\"model\"] == \"Qwen/Qwen2.5-14B-Instruct\"]\n",
    "# df = df[df[\"prompt_name\"] == \"stringstate-1_0-k-goal+locations_visited+current_location+current_inventory+thought+action\"]\n",
    "\n",
    "print(df.shape)\n",
    "# display(df.head(5))\n",
    "\n",
    "\n",
    "def calc_successes(df):\n",
    "    # Group by env_type\n",
    "    grouped = df.groupby(\"env_type\")[\"success\"]\n",
    "    \n",
    "    # Compute success rate and count\n",
    "    success_stats = grouped.agg(\n",
    "        success_rate=lambda x: 100 * x.mean(),\n",
    "        count=\"count\"\n",
    "    ).round(2)\n",
    "    \n",
    "    # Print\n",
    "    print(\"Success Rate and Count by env_type (before filtering):\")\n",
    "    print(success_stats.to_string())\n",
    "\n",
    "calc_successes(df)\n",
    "\n",
    "# 4. Filter out failed trials or include all\n",
    "df = df[df[\"success\"] == True].reset_index(drop=True)\n",
    "\n",
    "# 5. Create a Hugging Face Dataset\n",
    "# Drop the original file path columns if not needed\n",
    "# columns_to_drop = [\"prompt_file\", \"trace_file\"]\n",
    "\n",
    "\n",
    "def extract_whole_trace(example):\n",
    "    # print(example[\"trace_file\"])\n",
    "    filename = os.path.basename(example[\"trace_file\"])\n",
    "    # print(filename)\n",
    "    trace = json.load(open(PROMPT_BASE_DIR + filename))\n",
    "\n",
    "    # Prompt = system + initial user\n",
    "    sys_msg  = next(m[\"content\"] for m in trace if m[\"role\"]==\"system\")\n",
    "    usr_msg  = next(m[\"content\"] for m in trace if m[\"role\"]==\"user\")\n",
    "\n",
    "    # print(usr_msg)\n",
    "    prompt   = sys_msg + \"\\n\" + usr_msg + \"\\n\"\n",
    "    # Completion = *everything else*, in order\n",
    "    rest     = trace[2:]\n",
    "    completion = \"\".join(m[\"content\"] + \"\\n\" for m in rest)\n",
    "    # add end‐of‐sequence token if needed\n",
    "    if not completion.endswith(\"\"):\n",
    "        completion += \"\"\n",
    "        \n",
    "    match = re.findall(\"Nothing happens.\", completion)\n",
    "    # if len(match) > 0:\n",
    "    #     print(len(match))\n",
    "    \n",
    "    return {\"prompt\": prompt, \"completion\": completion, \"nothing_occ\":len(match)}\n",
    "\n",
    "def extract_final_trace(example, eos: str = \"\"):\n",
    "    \"\"\"\n",
    "    Build:\n",
    "      prompt     = system + first user\n",
    "      completion = last assistant message ONLY\n",
    "    If the last assistant has no 'content', fall back to 'old_content'.\n",
    "    \"\"\"\n",
    "    with open(example[\"trace_file\"], \"r\") as f:\n",
    "        trace = json.load(f)\n",
    "\n",
    "    # Prompt = first system + first user\n",
    "    sys_msg = next((m.get(\"content\", \"\") for m in trace if m.get(\"role\") == \"system\"), \"\")\n",
    "    usr_msg = next((m.get(\"content\", \"\") for m in trace if m.get(\"role\") == \"user\"), \"\")\n",
    "    prompt  = (sys_msg + \"\\n\" + usr_msg).rstrip() + \"\\n\"\n",
    "\n",
    "    # Completion = only the final assistant message\n",
    "    last_assistant = next((m for m in reversed(trace) if m.get(\"role\") == \"assistant\"), None)\n",
    "\n",
    "    completion = last_assistant.get(\"content\") or last_assistant.get(\"old_content\") or \"\"\n",
    "    completion = completion.rstrip() + \"\\n\"\n",
    "\n",
    "    # Optional EOS token\n",
    "    if eos and not completion.endswith(eos):\n",
    "        completion += eos\n",
    "\n",
    "    return {\"prompt\": prompt, \"completion\": completion}\n",
    "\n",
    "# apply to your pandas DataFrame before converting to a HF Dataset:\n",
    "df[[\"prompt\", \"completion\", \"nothing_occ\"]] = df.apply(lambda row: pd.Series(extract_whole_trace(row)), axis=1)\n",
    "\n",
    "# removed_examples = len(df[df.nothing_occ != 0])\n",
    "# df = df[df.nothing_occ == 0]\n",
    "\n",
    "removed_examples = len(df[df.nothing_occ >= 2])\n",
    "df = df[df.nothing_occ < 2]\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(\"\\n\"+\"*\"*50 + f\"\\nTotal removed examples (with nothing happened): {removed_examples}\\n\" + \"*\"*50)\n",
    "# df[[\"prompt\", \"completion\"]] = df.apply(lambda row: pd.Series(extract_final_trace(row)), axis=1)\n",
    "\n",
    "calc_successes(df)\n",
    "\n",
    "print(\"\\n\"+\"*\"*50 + f\"\\nFinal Dataset Size {len(df)}\\n\" + \"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb87c712-1580-473f-b041-0be048720d8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interact with a household to solve a task.\n",
      "\n",
      "\n",
      "============\n",
      "\n",
      "Here are 2 examples:\n",
      "\n",
      "You are in the middle of a room. Looking quickly around you, you see a cabinet 13, a cabinet 12, a cabinet 11, a cabinet 10, a cabinet 9, a cabinet 8, a cabinet 7, a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a countertop 1, a diningtable 1, a drawer 1, a fridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin 1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.\n",
      "Your task is to: put a hot apple in fridge.\n",
      "> think: To solve the task, I need to find and take an apple, then heat it with microwave, then put it in fridge.\n",
      "OK.\n",
      "> think: First I need to find an apple. An apple is more likely to appear in fridge (1), diningtable (1), coffeetable (1), drawer (1), cabinet (1-13), garbagecan (1). I can check one by one, starting with fridge 1.\n",
      "OK.\n",
      "> go to fridge 1\n",
      "The fridge 1 is closed.\n",
      "> open fridge 1\n",
      "You open the fridge 1. The fridge 1 is open. In it, you see a cup 1, and a egg 1.\n",
      "> go to diningtable 1\n",
      "On the diningtable 1, you see a apple 1, a bread 1, a fork 3, a fork 2, a fork 1, a mug 2, a peppershaker 3, a plate 2, a pot 1, a soapbottle 3, a spatula 1, a spoon 3, a spoon 2, a spoon 1, a winebottle 3, and a winebottle 2.\n",
      "> think: Now I find an apple (1). Next, I need to take it.\n",
      "OK.\n",
      "> take apple 1 from diningtable 1\n",
      "You pick up the apple 1 from the diningtable 1.\n",
      "> think: Now I take an apple (1). Next, I need to go to a microwave (1) and heat it.\n",
      "OK.\n",
      "> go to microwave 1\n",
      "The microwave 1 is closed.\n",
      "> heat apple 1 with microwave 1\n",
      "You heat the apple 1 using the microwave 1.\n",
      "> think: Now I heat an apple (1). Next, I need to put it in/on fridge 1.\n",
      "OK.\n",
      "> go to fridge 1\n",
      "The fridge 1 is open. In it, you see a cup 1, and a egg 1.\n",
      "> put apple 1 in/on fridge 1\n",
      "You put the apple 1 in/on the fridge 1.\n",
      "\n",
      "\n",
      "You are in the middle of a room. Looking quickly around you, you see a cabinet 10, a cabinet 9, a cabinet 8, a cabinet 7, a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a countertop 3, a countertop 2, a countertop 1, a diningtable 1, a drawer 6, a drawer 5, a drawer 4, a drawer 3, a drawer 2, a drawer 1, a fridge 1, a garbagecan 1, a microwave 1, a sinkbasin 1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.\n",
      "Your task is to: heat some egg and put it in diningtable.\n",
      "> think: To solve the task, I need to find and take an egg, then heat it with microwave, then put it in diningtable.\n",
      "OK.\n",
      "> think: First I need to find an egg. An egg is more likely to appear in fridge (1), countertop (1-3), diningtable (1), stoveburner (1-4), toaster (1), garbagecan (1), cabinet (1-10). I can check one by one, starting with fridge 1.\n",
      "OK.\n",
      "> go to fridge 1\n",
      "The fridge 1 is closed.\n",
      "> open fridge 1\n",
      "You open the fridge 1. The fridge 1 is open. In it, you see a lettuce 2, a mug 2, and a potato 3.\n",
      "> go to countertop 1\n",
      "On the countertop 1, you see a bread 1, a fork 1, and a saltshaker 1.\n",
      "> go to countertop 2\n",
      "On the countertop 2, you see nothing.\n",
      "> go to countertop 3\n",
      "On the countertop 3, you see a bowl 1, a butterknife 1, a egg 2, a kettle 2, a plate 1, a sink 1, and a spatula 2.\n",
      "> think: Now I find an egg (2). Next, I need to take it.\n",
      "OK.\n",
      "> take egg 2 from countertop 3\n",
      "You pick up the egg 2 from the countertop 3.\n",
      "> think: Now I take an egg (2). Next, I need go to a microwave (1) and heat it.\n",
      "OK.\n",
      "> go to microwave 1\n",
      "The microwave 1 is closed.\n",
      "> heat egg 2 with microwave 1\n",
      "You heat the egg 2 using the microwave 1.\n",
      "> think: Now I heat an egg (2). Next, I need to put it in/on diningtable 1.\n",
      "OK.\n",
      "> go to diningtable 1\n",
      "On the diningtable 1, you see a apple 2, a bread 3, a egg 1, a kettle 1, a knife 1, a mug 1, a papertowelroll 1, a peppershaker 2, a potato 1, a soapbottle 1, and a spatula 1.\n",
      "> put egg 2 in/on diningtable 1\n",
      "You put the egg 2 in/on the diningtable 1.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============\n",
      "\n",
      "Here is the task.\n",
      "\n",
      "\n",
      "You are in the middle of a room. Looking quickly around you, you see a cabinet 20, a cabinet 19, a cabinet 18, a cabinet 17, a cabinet 16, a cabinet 15, a cabinet 14, a cabinet 13, a cabinet 12, a cabinet 11, a cabinet 10, a cabinet 9, a cabinet 8, a cabinet 7, a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a countertop 3, a countertop 2, a countertop 1, a drawer 3, a drawer 2, a drawer 1, a fridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin 1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.\n",
      "Your task is to: put a hot potato in garbagecan.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = df.prompt[0]\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1fe692c5-bc5d-4102-8466-d1134f293bcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env_idx</th>\n",
       "      <th>env_type</th>\n",
       "      <th>agent_type</th>\n",
       "      <th>llm_type</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>success</th>\n",
       "      <th>done</th>\n",
       "      <th>total_reward</th>\n",
       "      <th>...</th>\n",
       "      <th>resample</th>\n",
       "      <th>resample_temperature</th>\n",
       "      <th>keys_to_use</th>\n",
       "      <th>additional_prompt_annotation</th>\n",
       "      <th>trace_file</th>\n",
       "      <th>prompt_file</th>\n",
       "      <th>env_reference</th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "      <th>nothing_occ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>examine</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>look_at_obj_in_light-KeyChain-None-DeskLamp-30...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: look at keychain under the desklamp\\nlo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>401</td>\n",
       "      <td>puttwo</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>pick_two_obj_and_place-CreditCard-None-SideTab...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: put two creditcards in sidetable\\nlocat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>puttwo</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>pick_two_obj_and_place-Watch-None-SideTable-21...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: find two watches and put them in sideta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>puttwo</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>pick_two_obj_and_place-Pillow-None-Ottoman-208...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: find two pillows and put them in ottoma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>puttwo</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>pick_two_obj_and_place-Laptop-None-Bed-311/tri...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: put two laptops in bed\\nlocations visit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   env_idx env_type agent_type  llm_type                      model  \\\n",
       "0        5  examine  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "1      401   puttwo  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "2        7   puttwo  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "3        8   puttwo  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "4       11   puttwo  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "\n",
       "   temperature                                        prompt_name  success  \\\n",
       "0          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "1          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "2          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "3          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "4          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "\n",
       "   done  total_reward  ... resample  resample_temperature  \\\n",
       "0  True             1  ...    False                   NaN   \n",
       "1  True             1  ...    False                   NaN   \n",
       "2  True             1  ...    False                   NaN   \n",
       "3  True             1  ...    False                   NaN   \n",
       "4  True             1  ...    False                   NaN   \n",
       "\n",
       "                                         keys_to_use  \\\n",
       "0  ['goal', 'locations_visited', 'current_locatio...   \n",
       "1  ['goal', 'locations_visited', 'current_locatio...   \n",
       "2  ['goal', 'locations_visited', 'current_locatio...   \n",
       "3  ['goal', 'locations_visited', 'current_locatio...   \n",
       "4  ['goal', 'locations_visited', 'current_locatio...   \n",
       "\n",
       "   additional_prompt_annotation  \\\n",
       "0                           NaN   \n",
       "1                           NaN   \n",
       "2                           NaN   \n",
       "3                           NaN   \n",
       "4                           NaN   \n",
       "\n",
       "                                          trace_file  \\\n",
       "0  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "1  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "2  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "3  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "4  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "\n",
       "                                         prompt_file  \\\n",
       "0  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "1  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "2  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "3  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "4  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "\n",
       "                                       env_reference  \\\n",
       "0  look_at_obj_in_light-KeyChain-None-DeskLamp-30...   \n",
       "1  pick_two_obj_and_place-CreditCard-None-SideTab...   \n",
       "2  pick_two_obj_and_place-Watch-None-SideTable-21...   \n",
       "3  pick_two_obj_and_place-Pillow-None-Ottoman-208...   \n",
       "4  pick_two_obj_and_place-Laptop-None-Bed-311/tri...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Interact with a household to solve a task.\\n\\n...   \n",
       "1  Interact with a household to solve a task.\\n\\n...   \n",
       "2  Interact with a household to solve a task.\\n\\n...   \n",
       "3  Interact with a household to solve a task.\\n\\n...   \n",
       "4  Interact with a household to solve a task.\\n\\n...   \n",
       "\n",
       "                                          completion  nothing_occ  \n",
       "0  >goal: look at keychain under the desklamp\\nlo...            0  \n",
       "1  >goal: put two creditcards in sidetable\\nlocat...            0  \n",
       "2  >goal: find two watches and put them in sideta...            0  \n",
       "3  >goal: find two pillows and put them in ottoma...            0  \n",
       "4  >goal: put two laptops in bed\\nlocations visit...            0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[\"env_type\"].isin([\"puttwo\", \"examine\"])]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# df = df[df[\"num_of_steps\"]>=df.num_of_steps.mean()]\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e2a9f16e-f03c-4175-a129-682e4815b12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nothing_occ\n",
       "0    120\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.nothing_occ[:120].mean())\n",
    "df.nothing_occ[:120].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7558bb59-4396-48ff-8180-a919d75bda54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nothing_occ\n",
       "0    781\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.nothing_occ.mean())\n",
    "df.nothing_occ.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4953ea6-ae8c-493e-b020-fd2941be334f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Interact with a household to solve a task.\\n\\n\\n============\\nApply these rules silently to choose the next action.\\nNever repeat, quote, or paraphrase this block in thought or action.\\nIf any rule conflicts with the current observation, prefer the observation.\\n\\n=========\\nHere are some hints:\\n- Prioritize searching areas where the {object} is likely to be found.\\n- Verify the presence of the {object} in the environment before proceeding.\\n- Prioritize searching locations likely to contain the {object} needed for the task.\\n=========\\n\\n============\\n\\nHere are 2 examples:\\n\\nYou are in the middle of a room. Looking quickly around you, you see a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a countertop 1, a diningtable 3, a diningtable 2, a diningtable 1, a drawer 1, a fridge 1, a garbagecan 1, a microwave 1, a sidetable 1, a sinkbasin 1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.\\nYour task is to: clean some apple and put it in sidetable.\\n\\n>goal: clean some apple and put it in sidetable\\nlocations visited: None\\ncurrent location: starting location\\ncurrent inventory: None\\nthought: To solve the task, I need to find and take an apple, then clean it with sinkbasin, then put it in sidetable. First I need to find an apple. An apple is more likely to appear in fridges (1), diningtable (1-3), sidetable (1), countertop (1), sinkbasin (1), garbagecan (1). I can check one by one, starting with fridge 1.\\naction: go to fridge 1\\n\\nThe fridge 1 is closed.\\n\\n>goal: clean some apple and put it in sidetable\\nlocations visited: fridge 1\\ncurrent location: fridge 1\\ncurrent inventory: None\\nthought: None\\naction: open fridge 1\\n\\nYou open the fridge 1. The fridge 1 is open. In it, you see a lettuce 2, a mug 2, a potato 2, and a tomato 1.\\n\\n>goal: clean some apple and put it in sidetable\\nlocations visited: fridge 1\\ncurrent location: fridge 1\\ncurrent inventory: None\\nthought: None\\naction: go to diningtable 1\\n\\nOn the diningtable 1, you see nothing.\\n\\n>goal: clean some apple and put it in sidetable\\nlocations visited: fridge 1, diningtable 1\\ncurrent location: diningtable 1\\ncurrent inventory: None\\nthought: None\\naction: go to diningtable 2\\n\\nOn the diningtable 2, you see a pineapple 1.\\n\\n>goal: clean some apple and put it in sidetable\\nlocations visited: fridge 1, diningtable 1, diningtable 2\\ncurrent location: diningtable 2\\ncurrent inventory: None\\nthought: None\\naction: go to diningtable 3\\n\\nOn the diningtable 3, you see a bowl 2, a bowl 1, a bread 2, and a bread 1.\\n\\n>goal: clean some apple and put it in sidetable\\nlocations visited: fridge 1, diningtable 1, diningtable 2, diningtable 3\\ncurrent location: diningtable 3\\ncurrent inventory: None\\nthought: None\\naction: go to sidetable 1\\n\\nOn the sidetable 1, you see a cup 1, a lettuce 1, a peppershaker 3, a potato 1, and a saltshaker 1.\\n\\n>goal: clean some apple and put it in sidetable\\nlocations visited: fridge 1, diningtable 1, diningtable 2, diningtable 3, sidetable 1\\ncurrent location: sidetable 1\\ncurrent inventory: None\\nthought: None\\naction: go to countertop 1\\n\\nOn the countertop 1, you see a butterknife 1, a dishsponge 1, and a soapbottle 1.\\n\\n>goal: clean some apple and put it in sidetable\\nlocations visited: fridge 1, diningtable 1, diningtable 2, diningtable 3, sidetable 1, countertop 1\\ncurrent location: countertop 1\\ncurrent inventory: None\\nthought: None\\naction: go to sinkbasin 1\\n\\nOn the sinkbasin 1, you see a cup 2, a egg 1, a mug 1, and a potato 3.\\n\\n>goal: clean some apple and put it in sidetable\\nlocations visited: fridge 1, diningtable 1, diningtable 2, diningtable 3, sidetable 1, countertop 1, sinkbasin 1\\ncurrent location: sinkbasin 1\\ncurrent inventory: None\\nthought: None\\naction: go to garbagecan 1\\n\\nOn the garbagecan 1, you see a apple 3, and a egg 3.\\n\\n>goal: clean some apple and put it in sidetable\\nlocations visited: fridge 1, diningtable 1, diningtable 2, diningtable 3, sidetable 1, countertop 1, sinkbasin 1, garbagecan 1\\ncurrent location: garbagecan 1\\ncurrent inventory: None\\nthought: Now I find an apple (3). Next, I need to take it.\\naction: take apple 3 from garbagecan 1\\n\\nYou pick up the apple 3 from the garbagecan 1.\\n\\n>goal: clean some apple and put it in sidetable\\nlocations visited: fridge 1, diningtable 1, diningtable 2, diningtable 3, sidetable 1, countertop 1, sinkbasin 1, garbagecan 1\\ncurrent location: garbagecan 1\\ncurrent inventory: apple 3\\nthought: Now I take an apple (3). Next, I need to go to sinkbasin (1) and clean it.\\naction: go to sinkbasin 1\\n\\nOn the sinkbasin 1, you see a cup 2, a egg 1, a mug 1, and a potato 3.\\n\\n>goal: clean some apple and put it in sidetable\\nlocations visited: fridge 1, diningtable 1, diningtable 2, diningtable 3, sidetable 1, countertop 1, sinkbasin 1, garbagecan 1, sinkbasin 1\\ncurrent location: sinkbasin 1\\ncurrent inventory: apple 3\\nthought: None\\naction: clean apple 3 with sinkbasin 1\\n\\nYou clean the apple 3 using the sinkbasin 1.\\n\\n>goal: clean some apple and put it in sidetable\\nlocations visited: fridge 1, diningtable 1, diningtable 2, diningtable 3, sidetable 1, countertop 1, sinkbasin 1, garbagecan 1, sinkbasin 1\\ncurrent location: sinkbasin 1\\ncurrent inventory: apple 3\\nthought: Now I clean an apple (3). Next, I need to put it in/on sidetable 1.\\naction: go to sidetable 1\\n\\nOn the sidetable 1, you see a cup 1, a lettuce 1, a peppershaker 3, a potato 1, and a saltshaker 1.\\n\\n>goal: clean some apple and put it in sidetable\\nlocations visited: fridge 1, diningtable 1, diningtable 2, diningtable 3, sidetable 1, countertop 1, sinkbasin 1, garbagecan 1, sinkbasin 1, sidetable 1\\ncurrent location: sidetable 1\\ncurrent inventory: apple 3\\nthought: None\\naction: put apple 3 in/on sidetable 1\\n\\n\\n\\nYou are in the middle of a room. Looking quickly around you, you see a cabinet 13, a cabinet 12, a cabinet 11, a cabinet 10, a cabinet 9, a cabinet 8, a cabinet 7, a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a countertop 1, a diningtable 1, a drawer 1, a fridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin 1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.\\nYour task is to: put a clean lettuce in diningtable.\\n\\n>goal: put a clean lettuce in diningtable\\nlocations visited: None\\ncurrent location: starting location\\ncurrent inventory: None\\nthought: To solve the task, I need to find and take a lettuce, then clean it with sinkbasin, then put it in diningtable. First I need to find a lettuce. A lettuce is more likely to appear in fridge (1), diningtable (1), sinkbasin (1), stoveburner (1-3), cabinet (1-13). I can check one by one, starting with fridge 1.\\naction: go to fridge 1\\n\\nThe fridge 1 is closed.\\n\\n>goal: put a clean lettuce in diningtable\\nlocations visited: fridge 1\\ncurrent location: fridge 1\\ncurrent inventory: None\\nthought: None\\naction: open fridge 1\\n\\nYou open the fridge 1. The fridge 1 is open. In it, you see a cup 3, a egg 2, a potato 3, and a potato 2.\\n\\n>goal: put a clean lettuce in diningtable\\nlocations visited: fridge 1\\ncurrent location: fridge 1\\ncurrent inventory: None\\nthought: None\\naction: go to diningtable 1\\n\\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a fork 2, a knife 2, a knife 1, a ladle 1, a lettuce 1, a mug 2, a mug 1, a pan 2, a peppershaker 1, a spatula 3, a tomato 2, and a tomato 1.\\n\\n>goal: put a clean lettuce in diningtable\\nlocations visited: fridge 1, diningtable 1\\ncurrent location: diningtable 1\\ncurrent inventory: None\\nthought: Now I find a lettuce (1). Next, I need to take it.\\naction: take lettuce 1 from diningtable 1\\n\\nYou pick up the lettuce 1 from the diningtable 1.\\n\\n>goal: put a clean lettuce in diningtable\\nlocations visited: fridge 1, diningtable 1\\ncurrent location: diningtable 1\\ncurrent inventory: lettuce 1\\nthought: Now I take a lettuce (1). Next, I need to go to sinkbasin (1) and clean it.\\naction: go to sinkbasin 1\\n\\nOn the sinkbasin 1, you see a apple 2, a ladle 2, a spoon 1, and a tomato 3.\\n\\n>goal: put a clean lettuce in diningtable\\nlocations visited: fridge 1, diningtable 1, sinkbasin 1\\ncurrent location: sinkbasin 1\\ncurrent inventory: lettuce 1\\nthought: None\\naction: clean lettuce 1 with sinkbasin 1\\n\\nYou clean the lettuce 1 using the sinkbasin 1.\\n\\n>goal: put a clean lettuce in diningtable\\nlocations visited: fridge 1, diningtable 1, sinkbasin 1\\ncurrent location: sinkbasin 1\\ncurrent inventory: lettuce 1\\nthought: Now I clean a lettuce (1). Next, I need to put it in/on diningtable 1.\\naction: go to diningtable 1\\n\\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a fork 2, a knife 2, a knife 1, a ladle 1, a mug 2, a mug 1, a pan 2, a peppershaker 1, a spatula 3, a tomato 2, and a tomato 1.\\n\\n>goal: put a clean lettuce in diningtable\\nlocations visited: fridge 1, diningtable 1, sinkbasin 1, diningtable 1\\ncurrent location: diningtable 1\\ncurrent inventory: lettuce 1\\nthought: None\\naction: put lettuce 1 in/on diningtable 1\\n\\n\\n\\n\\n============\\n\\nHere is the task.\\n\\n\\nYou are in the middle of a room. Looking quickly around you, you see a cabinet 16, a cabinet 15, a cabinet 14, a cabinet 13, a cabinet 12, a cabinet 11, a cabinet 10, a cabinet 9, a cabinet 8, a cabinet 7, a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a countertop 2, a countertop 1, a diningtable 1, a drawer 5, a drawer 4, a drawer 3, a drawer 2, a drawer 1, a fridge 1, a garbagecan 1, a microwave 1, a safe 1, a sinkbasin 1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.\\nYour task is to: put a clean spoon in diningtable.\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.prompt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49c6b759-4305-488f-a6d5-7c560ad83bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Steps Statistics\n",
      "***************************\n",
      "Min 4\n",
      "25th 7.0\n",
      "Median 9.0\n",
      "Mean 11.125\n",
      "75th 13.0\n",
      "Max 31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Steps Statistics\\n***************************\")\n",
    "print(f\"\"\"Min {df.num_of_steps.min()}\n",
    "25th {df.num_of_steps.quantile(.25)}\n",
    "Median {df.num_of_steps.median()}\n",
    "Mean {df.num_of_steps.mean()}\n",
    "75th {df.num_of_steps.quantile(.75)}\n",
    "Max {df.num_of_steps.max()}\n",
    "\"\"\")\n",
    "# df.num_of_steps.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4839850-000c-4c74-b23d-e0a9e7a41294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env_idx</th>\n",
       "      <th>env_type</th>\n",
       "      <th>agent_type</th>\n",
       "      <th>llm_type</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>success</th>\n",
       "      <th>done</th>\n",
       "      <th>total_reward</th>\n",
       "      <th>...</th>\n",
       "      <th>total_history_token</th>\n",
       "      <th>correction</th>\n",
       "      <th>resample</th>\n",
       "      <th>resample_temperature</th>\n",
       "      <th>keys_to_use</th>\n",
       "      <th>additional_prompt_annotation</th>\n",
       "      <th>trace_file</th>\n",
       "      <th>prompt_file</th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>heat</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2999</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: put a hot potato in garbagecan\\nlocatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>put</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3402</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: put a spraybottle in cabinet\\nlocations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>clean</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3480</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: put a clean mug in coffeemachine\\nlocat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>clean</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3944</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: clean some spoon and put it in diningta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>examine</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3728</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: look at keychain under the desklamp\\nlo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   env_idx env_type agent_type  llm_type                      model  \\\n",
       "0        1     heat  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "1        2      put  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "2        3    clean  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "3        4    clean  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "4        5  examine  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "\n",
       "   temperature                                        prompt_name  success  \\\n",
       "0          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "1          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "2          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "3          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "4          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "\n",
       "   done  total_reward  ... total_history_token  correction  resample  \\\n",
       "0  True             1  ...                2999        True     False   \n",
       "1  True             1  ...                3402        True     False   \n",
       "2  True             1  ...                3480        True     False   \n",
       "3  True             1  ...                3944        True     False   \n",
       "4  True             1  ...                3728        True     False   \n",
       "\n",
       "   resample_temperature                                        keys_to_use  \\\n",
       "0                   NaN  ['goal', 'locations_visited', 'current_locatio...   \n",
       "1                   NaN  ['goal', 'locations_visited', 'current_locatio...   \n",
       "2                   NaN  ['goal', 'locations_visited', 'current_locatio...   \n",
       "3                   NaN  ['goal', 'locations_visited', 'current_locatio...   \n",
       "4                   NaN  ['goal', 'locations_visited', 'current_locatio...   \n",
       "\n",
       "   additional_prompt_annotation  \\\n",
       "0                           NaN   \n",
       "1                           NaN   \n",
       "2                           NaN   \n",
       "3                           NaN   \n",
       "4                           NaN   \n",
       "\n",
       "                                          trace_file  \\\n",
       "0  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "1  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "2  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "3  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "4  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "\n",
       "                                         prompt_file  \\\n",
       "0  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "1  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "2  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "3  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "4  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Interact with a household to solve a task.\\n\\n...   \n",
       "1  Interact with a household to solve a task.\\n\\n...   \n",
       "2  Interact with a household to solve a task.\\n\\n...   \n",
       "3  Interact with a household to solve a task.\\n\\n...   \n",
       "4  Interact with a household to solve a task.\\n\\n...   \n",
       "\n",
       "                                          completion  \n",
       "0  >goal: put a hot potato in garbagecan\\nlocatio...  \n",
       "1  >goal: put a spraybottle in cabinet\\nlocations...  \n",
       "2  >goal: put a clean mug in coffeemachine\\nlocat...  \n",
       "3  >goal: clean some spoon and put it in diningta...  \n",
       "4  >goal: look at keychain under the desklamp\\nlo...  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88db6c3f-5f18-466e-aabd-0ef8579ee504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env_idx</th>\n",
       "      <th>env_type</th>\n",
       "      <th>agent_type</th>\n",
       "      <th>llm_type</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>success</th>\n",
       "      <th>done</th>\n",
       "      <th>total_reward</th>\n",
       "      <th>...</th>\n",
       "      <th>total_history_token</th>\n",
       "      <th>correction</th>\n",
       "      <th>resample</th>\n",
       "      <th>resample_temperature</th>\n",
       "      <th>keys_to_use</th>\n",
       "      <th>additional_prompt_annotation</th>\n",
       "      <th>trace_file</th>\n",
       "      <th>prompt_file</th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>examine</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3728</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: look at keychain under the desklamp\\nlo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>puttwo</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3823</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: find two watches and put them in sideta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>puttwo</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3126</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: find two pillows and put them in ottoma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>puttwo</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3079</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: put two laptops in bed\\nlocations visit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>401</td>\n",
       "      <td>puttwo</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4566</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: put two creditcards in sidetable\\nlocat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   env_idx env_type agent_type  llm_type                      model  \\\n",
       "0        5  examine  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "1        7   puttwo  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "2        8   puttwo  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "3       11   puttwo  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "4      401   puttwo  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "\n",
       "   temperature                                        prompt_name  success  \\\n",
       "0          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "1          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "2          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "3          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "4          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "\n",
       "   done  total_reward  ... total_history_token  correction  resample  \\\n",
       "0  True             1  ...                3728        True     False   \n",
       "1  True             1  ...                3823        True     False   \n",
       "2  True             1  ...                3126        True     False   \n",
       "3  True             1  ...                3079        True     False   \n",
       "4  True             1  ...                4566        True     False   \n",
       "\n",
       "   resample_temperature                                        keys_to_use  \\\n",
       "0                   NaN  ['goal', 'locations_visited', 'current_locatio...   \n",
       "1                   NaN  ['goal', 'locations_visited', 'current_locatio...   \n",
       "2                   NaN  ['goal', 'locations_visited', 'current_locatio...   \n",
       "3                   NaN  ['goal', 'locations_visited', 'current_locatio...   \n",
       "4                   NaN  ['goal', 'locations_visited', 'current_locatio...   \n",
       "\n",
       "   additional_prompt_annotation  \\\n",
       "0                           NaN   \n",
       "1                           NaN   \n",
       "2                           NaN   \n",
       "3                           NaN   \n",
       "4                           NaN   \n",
       "\n",
       "                                          trace_file  \\\n",
       "0  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "1  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "2  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "3  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "4  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "\n",
       "                                         prompt_file  \\\n",
       "0  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "1  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "2  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "3  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "4  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Interact with a household to solve a task.\\n\\n...   \n",
       "1  Interact with a household to solve a task.\\n\\n...   \n",
       "2  Interact with a household to solve a task.\\n\\n...   \n",
       "3  Interact with a household to solve a task.\\n\\n...   \n",
       "4  Interact with a household to solve a task.\\n\\n...   \n",
       "\n",
       "                                          completion  \n",
       "0  >goal: look at keychain under the desklamp\\nlo...  \n",
       "1  >goal: find two watches and put them in sideta...  \n",
       "2  >goal: find two pillows and put them in ottoma...  \n",
       "3  >goal: put two laptops in bed\\nlocations visit...  \n",
       "4  >goal: put two creditcards in sidetable\\nlocat...  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[\"env_type\"].isin([\"puttwo\", \"examine\"])]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "704de746-86d3-4dd9-b2f3-93133d75e7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "Success Rate and Count by env_type (before filtering):\n",
      "          success_rate  count\n",
      "env_type                     \n",
      "clean            100.0     61\n",
      "cool             100.0     23\n",
      "examine          100.0     19\n",
      "heat             100.0     17\n",
      "put              100.0     66\n",
      "puttwo           100.0     69\n"
     ]
    }
   ],
   "source": [
    "df = df[df[\"num_of_steps\"]>=df.num_of_steps.mean()]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(len(df))\n",
    "df.head()\n",
    "\n",
    "calc_successes(df)\n",
    "\n",
    "# df = df[df[\"num_of_steps\"]<=df.num_of_steps.quantile(.25)]\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "# print(len(df))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eda4293-991d-4d5a-9832-59c613df8cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env_idx</th>\n",
       "      <th>env_type</th>\n",
       "      <th>agent_type</th>\n",
       "      <th>llm_type</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>success</th>\n",
       "      <th>done</th>\n",
       "      <th>total_reward</th>\n",
       "      <th>...</th>\n",
       "      <th>correction</th>\n",
       "      <th>resample</th>\n",
       "      <th>resample_temperature</th>\n",
       "      <th>keys_to_use</th>\n",
       "      <th>additional_prompt_annotation</th>\n",
       "      <th>trace_file</th>\n",
       "      <th>prompt_file</th>\n",
       "      <th>env_reference</th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>414</td>\n",
       "      <td>put</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>pick_and_place_simple-CD-None-DiningTable-311/...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: put a cd in diningtable\\nlocations visi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>put</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>pick_and_place_simple-SoapBottle-None-Cart-430...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: put some soapbottle on cart\\nlocations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>808</td>\n",
       "      <td>put</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>pick_and_place_simple-Pen-None-Shelf-319/trial...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: put a pen in shelf\\nlocations visited: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>810</td>\n",
       "      <td>puttwo</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>pick_two_obj_and_place-Pen-None-Drawer-311/tri...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: put two pens in drawer\\nlocations visit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>815</td>\n",
       "      <td>examine</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>look_at_obj_in_light-CD-None-DeskLamp-305/tria...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: examine the cd with the desklamp\\nlocat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   env_idx env_type agent_type  llm_type                      model  \\\n",
       "0      414      put  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "1       25      put  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "2      808      put  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "3      810   puttwo  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "4      815  examine  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "\n",
       "   temperature                                        prompt_name  success  \\\n",
       "0          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "1          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "2          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "3          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "4          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "\n",
       "   done  total_reward  ... correction  resample  resample_temperature  \\\n",
       "0  True             1  ...       True     False                   NaN   \n",
       "1  True             1  ...       True     False                   NaN   \n",
       "2  True             1  ...       True     False                   NaN   \n",
       "3  True             1  ...       True     False                   NaN   \n",
       "4  True             1  ...       True     False                   NaN   \n",
       "\n",
       "                                         keys_to_use  \\\n",
       "0  ['goal', 'locations_visited', 'current_locatio...   \n",
       "1  ['goal', 'locations_visited', 'current_locatio...   \n",
       "2  ['goal', 'locations_visited', 'current_locatio...   \n",
       "3  ['goal', 'locations_visited', 'current_locatio...   \n",
       "4  ['goal', 'locations_visited', 'current_locatio...   \n",
       "\n",
       "   additional_prompt_annotation  \\\n",
       "0                           NaN   \n",
       "1                           NaN   \n",
       "2                           NaN   \n",
       "3                           NaN   \n",
       "4                           NaN   \n",
       "\n",
       "                                          trace_file  \\\n",
       "0  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "1  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "2  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "3  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "4  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "\n",
       "                                         prompt_file  \\\n",
       "0  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "1  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "2  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "3  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "4  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "\n",
       "                                       env_reference  \\\n",
       "0  pick_and_place_simple-CD-None-DiningTable-311/...   \n",
       "1  pick_and_place_simple-SoapBottle-None-Cart-430...   \n",
       "2  pick_and_place_simple-Pen-None-Shelf-319/trial...   \n",
       "3  pick_two_obj_and_place-Pen-None-Drawer-311/tri...   \n",
       "4  look_at_obj_in_light-CD-None-DeskLamp-305/tria...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Interact with a household to solve a task.\\n\\n...   \n",
       "1  Interact with a household to solve a task.\\n\\n...   \n",
       "2  Interact with a household to solve a task.\\n\\n...   \n",
       "3  Interact with a household to solve a task.\\n\\n...   \n",
       "4  Interact with a household to solve a task.\\n\\n...   \n",
       "\n",
       "                                          completion  \n",
       "0  >goal: put a cd in diningtable\\nlocations visi...  \n",
       "1  >goal: put some soapbottle on cart\\nlocations ...  \n",
       "2  >goal: put a pen in shelf\\nlocations visited: ...  \n",
       "3  >goal: put two pens in drawer\\nlocations visit...  \n",
       "4  >goal: examine the cd with the desklamp\\nlocat...  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q75 = df.num_of_steps.quantile(.75)\n",
    "df = df[df[\"num_of_steps\"]>=df.num_of_steps.mean()]\n",
    "df = df[df[\"num_of_steps\"]<=q75]\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "881fede9-9616-46d9-81f8-5e6aa8614e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "env_type\n",
       "put        86\n",
       "puttwo     69\n",
       "clean      55\n",
       "examine    29\n",
       "cool       25\n",
       "heat       25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.env_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c43afd9-ae88-461a-ba4b-b223a6e395fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Steps Statistics\\n***************************\")\n",
    "print(f\"\"\"Min {df.num_of_steps.min()}\n",
    "25th {df.num_of_steps.quantile(.25)}\n",
    "Median {df.num_of_steps.median()}\n",
    "Mean {df.num_of_steps.mean()}\n",
    "75th {df.num_of_steps.quantile(.75)}\n",
    "Max {df.num_of_steps.max()}\n",
    "\"\"\")\n",
    "# df.num_of_steps.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94098e8e-9fab-4983-ac42-0c5a8e6ab8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to entire DataFrame\n",
    "df[\"prompt\"] = df[\"prompt\"].apply(remove_few_shot_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8e14024-d1a6-4ae4-8ce7-433c645fd775",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Interact with a household to solve a task.\\n\\nYour task is to: put a hot potato in garbagecan.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.prompt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a21d96a-a521-4312-9578-aa386153a1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19\n",
       "1    21\n",
       "2    15\n",
       "3     7\n",
       "4    15\n",
       "5     9\n",
       "6    13\n",
       "7    11\n",
       "8    30\n",
       "9    15\n",
       "Name: num_of_steps, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:10].num_of_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6146cc21-3f02-4daf-ac4f-2f59f6f498a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = Dataset.from_pandas(df)\n",
    "dataset = Dataset.from_pandas(df.drop(columns=[\"success\", \"total_reward\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e6585c8-8f45-4a02-b92b-9adce3e797f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['env_idx', 'env_type', 'agent_type', 'llm_type', 'model', 'temperature', 'prompt_name', 'done', 'early_stop', 'error', 'num_of_steps', 'num_nothing_happens', 'num_repetitions', 'num_no_command', 'num_no_json', 'num_correction', 'num_resample', 'total_prompt_token', 'total_in_token_accumulated', 'total_in_token_message_accumulated', 'total_out_token_accumulated', 'total_history_token', 'correction', 'resample', 'resample_temperature', 'keys_to_use', 'additional_prompt_annotation', 'trace_file', 'prompt_file', 'env_reference', 'prompt', 'completion', 'nothing_occ'],\n",
       "    num_rows: 583\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d191017-acbc-4bce-a1e4-fb10f2aa968e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Interact with a household to solve a task.\\n\\nYour task is to: put a hot potato in garbagecan.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.prompt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44379f09-91e5-49ce-883b-e5e4b5642a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env_idx</th>\n",
       "      <th>env_type</th>\n",
       "      <th>agent_type</th>\n",
       "      <th>llm_type</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>success</th>\n",
       "      <th>done</th>\n",
       "      <th>total_reward</th>\n",
       "      <th>...</th>\n",
       "      <th>correction</th>\n",
       "      <th>resample</th>\n",
       "      <th>resample_temperature</th>\n",
       "      <th>keys_to_use</th>\n",
       "      <th>additional_prompt_annotation</th>\n",
       "      <th>trace_file</th>\n",
       "      <th>prompt_file</th>\n",
       "      <th>env_reference</th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>heat</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>pick_heat_then_place_in_recep-Potato-None-Garb...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: put a hot potato in garbagecan\\nlocatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>put</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>pick_and_place_simple-SprayBottle-None-Cabinet...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: put a spraybottle in cabinet\\nlocations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>403</td>\n",
       "      <td>put</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>pick_and_place_simple-Pan-None-CounterTop-8/tr...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: put a pan in countertop\\nlocations visi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>cool</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>pick_cool_then_place_in_recep-Plate-None-Cabin...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: cool some plate and put it in cabinet\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>410</td>\n",
       "      <td>cool</td>\n",
       "      <td>ours-text</td>\n",
       "      <td>VLLMChat</td>\n",
       "      <td>Qwen/Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stringstate-1_0-k-goal+locations_visited+curre...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['goal', 'locations_visited', 'current_locatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>game_logs/alfworld_eval_baseline_state_train_a...</td>\n",
       "      <td>pick_cool_then_place_in_recep-Bread-None-Micro...</td>\n",
       "      <td>Interact with a household to solve a task.\\n\\n...</td>\n",
       "      <td>&gt;goal: put a cool bread in microwave\\nlocation...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   env_idx env_type agent_type  llm_type                      model  \\\n",
       "0        1     heat  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "1        2      put  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "2      403      put  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "3       10     cool  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "4      410     cool  ours-text  VLLMChat  Qwen/Qwen2.5-14B-Instruct   \n",
       "\n",
       "   temperature                                        prompt_name  success  \\\n",
       "0          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "1          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "2          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "3          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "4          0.0  stringstate-1_0-k-goal+locations_visited+curre...     True   \n",
       "\n",
       "   done  total_reward  ... correction  resample  resample_temperature  \\\n",
       "0  True             1  ...       True     False                   NaN   \n",
       "1  True             1  ...       True     False                   NaN   \n",
       "2  True             1  ...       True     False                   NaN   \n",
       "3  True             1  ...       True     False                   NaN   \n",
       "4  True             1  ...       True     False                   NaN   \n",
       "\n",
       "                                         keys_to_use  \\\n",
       "0  ['goal', 'locations_visited', 'current_locatio...   \n",
       "1  ['goal', 'locations_visited', 'current_locatio...   \n",
       "2  ['goal', 'locations_visited', 'current_locatio...   \n",
       "3  ['goal', 'locations_visited', 'current_locatio...   \n",
       "4  ['goal', 'locations_visited', 'current_locatio...   \n",
       "\n",
       "   additional_prompt_annotation  \\\n",
       "0                           NaN   \n",
       "1                           NaN   \n",
       "2                           NaN   \n",
       "3                           NaN   \n",
       "4                           NaN   \n",
       "\n",
       "                                          trace_file  \\\n",
       "0  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "1  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "2  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "3  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "4  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "\n",
       "                                         prompt_file  \\\n",
       "0  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "1  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "2  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "3  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "4  game_logs/alfworld_eval_baseline_state_train_a...   \n",
       "\n",
       "                                       env_reference  \\\n",
       "0  pick_heat_then_place_in_recep-Potato-None-Garb...   \n",
       "1  pick_and_place_simple-SprayBottle-None-Cabinet...   \n",
       "2  pick_and_place_simple-Pan-None-CounterTop-8/tr...   \n",
       "3  pick_cool_then_place_in_recep-Plate-None-Cabin...   \n",
       "4  pick_cool_then_place_in_recep-Bread-None-Micro...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Interact with a household to solve a task.\\n\\n...   \n",
       "1  Interact with a household to solve a task.\\n\\n...   \n",
       "2  Interact with a household to solve a task.\\n\\n...   \n",
       "3  Interact with a household to solve a task.\\n\\n...   \n",
       "4  Interact with a household to solve a task.\\n\\n...   \n",
       "\n",
       "                                          completion  \n",
       "0  >goal: put a hot potato in garbagecan\\nlocatio...  \n",
       "1  >goal: put a spraybottle in cabinet\\nlocations...  \n",
       "2  >goal: put a pan in countertop\\nlocations visi...  \n",
       "3  >goal: cool some plate and put it in cabinet\\n...  \n",
       "4  >goal: put a cool bread in microwave\\nlocation...  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee23e9ea-4086-42a5-b51b-2be3931ead2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Steps Statistics\n",
      "***************************\n",
      "Min 11\n",
      "25th 13.0\n",
      "Median 16.0\n",
      "Mean 17.70980392156863\n",
      "75th 21.0\n",
      "Max 45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Steps Statistics\\n***************************\")\n",
    "print(f\"\"\"Min {df.num_of_steps.min()}\n",
    "25th {df.num_of_steps.quantile(.25)}\n",
    "Median {df.num_of_steps.median()}\n",
    "Mean {df.num_of_steps.mean()}\n",
    "75th {df.num_of_steps.quantile(.75)}\n",
    "Max {df.num_of_steps.max()}\n",
    "\"\"\")\n",
    "# df.num_of_steps.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a019833-7b07-42a1-8f03-5636eee4f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. (Optional) Split into train/validation\n",
    "# Here we do an 90/10 split; adjust 'seed' for reproducibility\n",
    "dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "train_ds = dataset[\"train\"]\n",
    "val_ds   = dataset[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1418569-34f4-40df-9a82-c284ba1ce776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['env_idx', 'env_type', 'agent_type', 'llm_type', 'model', 'temperature', 'prompt_name', 'done', 'early_stop', 'error', 'num_of_steps', 'num_nothing_happens', 'num_repetitions', 'num_no_command', 'num_no_json', 'num_correction', 'num_resample', 'total_prompt_token', 'total_in_token_accumulated', 'total_in_token_message_accumulated', 'total_out_token_accumulated', 'total_history_token', 'correction', 'resample', 'resample_temperature', 'keys_to_use', 'additional_prompt_annotation', 'trace_file', 'prompt_file', 'env_reference', 'prompt', 'completion', 'nothing_occ'],\n",
       "        num_rows: 681\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['env_idx', 'env_type', 'agent_type', 'llm_type', 'model', 'temperature', 'prompt_name', 'done', 'early_stop', 'error', 'num_of_steps', 'num_nothing_happens', 'num_repetitions', 'num_no_command', 'num_no_json', 'num_correction', 'num_resample', 'total_prompt_token', 'total_in_token_accumulated', 'total_in_token_message_accumulated', 'total_out_token_accumulated', 'total_history_token', 'correction', 'resample', 'resample_temperature', 'keys_to_use', 'additional_prompt_annotation', 'trace_file', 'prompt_file', 'env_reference', 'prompt', 'completion', 'nothing_occ'],\n",
       "        num_rows: 76\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14c47788-6e53-43d0-b934-cf10373d34ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536c457164274e3590dcc3d99cd036fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/789 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c121affcc4944b16b16f2d0d878a8898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/88 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset to hf_alfworld_dataset/vanilla_stateact_train1200\n"
     ]
    }
   ],
   "source": [
    "# 7. Save to disk for later fine-tuning\n",
    "OUT_DIR = \"hf_alfworld_dataset/vanilla_stateact_train1200\"\n",
    "# OUT_DIR = \"hf_alfworld_dataset/hints\"\n",
    "train_ds.save_to_disk(os.path.join(OUT_DIR, \"train\"))\n",
    "val_ds.save_to_disk(os.path.join(OUT_DIR, \"validation\"))\n",
    "\n",
    "print(f\"Saved dataset to {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db05302f-2816-4ee1-bc9c-bc01b24fb336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 09-01 10:04:46 [__init__.py:235] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from unsloth.chat_templates import train_on_responses_only\n",
    "\n",
    "def get_model_and_tokenizer(\n",
    "        model_name=\"Qwen/Qwen2.5-14B-Instruct\", \n",
    "        max_seq_length=1024,\n",
    "        load_in_4bit=True, \n",
    "        gpu_memory_utilization=0.9,\n",
    "        lora_rank=64,\n",
    "        random_state=1234,\n",
    "        get_peft=True,\n",
    "        # lora_alpha=64\n",
    "    ):\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = model_name ,\n",
    "        max_seq_length = max_seq_length,\n",
    "        load_in_4bit = load_in_4bit, # False for LoRA 16bit\n",
    "        load_in_8bit = False,    # A bit more accurate, uses 2x memory\n",
    "        full_finetuning = False, # We have full finetuning now!\n",
    "        fast_inference = False, # Enable vLLM fast inference\n",
    "        max_lora_rank = lora_rank,\n",
    "        gpu_memory_utilization = gpu_memory_utilization, # Reduce if out of memory\n",
    "        # device_map=\"cuda\" ,               # or {\"\": 0} to pin to GPU 0\n",
    "        device_map=\"auto\",               # pin everything to GPU 0\n",
    "        # trust_remote_code=True,\n",
    "    )\n",
    "\n",
    "    if get_peft:\n",
    "        model = FastLanguageModel.get_peft_model(\n",
    "            model,\n",
    "            r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "            target_modules = [\n",
    "                \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "            ], # Remove QKVO if out of memory\n",
    "            # lora_alpha = lora_rank,\n",
    "            lora_alpha = lora_rank*2,\n",
    "            \n",
    "            lora_dropout = 0.10,                    # add dropout (try 0.1–0.2)\n",
    "            \n",
    "            use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
    "            random_state = random_state,\n",
    "        )\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18c6c126-3fee-48db-b502-2d349a3f0768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "def get_sft_trainer(model, tokenizer, dataset, eval_dataset=None, training_steps=10, collator=None):\n",
    "    training_args = SFTConfig(\n",
    "        dataset_text_field = \"text\",\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4, # Use GA to mimic batch size!\n",
    "        # warmup_steps = 5,\n",
    "        # warmup_steps = 10,\n",
    "        warmup_ratio = 0.1,\n",
    "\n",
    "        # label_smoothing_factor=0.1,\n",
    "        num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        # max_steps = training_steps,\n",
    "        \n",
    "        learning_rate = 2e-4,\n",
    "        # learning_rate = 2e-5, # use for full train runs\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        \n",
    "        weight_decay = 0.01,\n",
    "        # weight_decay = 0.05, #increase to maybe improve\n",
    "        \n",
    "        lr_scheduler_type = \"linear\",\n",
    "        # lr_scheduler_type = \"cosine\",\n",
    "        seed = 42,\n",
    "        \n",
    "        # eval_strategy=\"steps\",\n",
    "        # eval_steps=3,                      # <-- frequency\n",
    "        \n",
    "        # report_to = \"none\", # Use this for WandB etc\n",
    "    )\n",
    "    \n",
    "    trainer = SFTTrainer(\n",
    "        model = model,\n",
    "        tokenizer = tokenizer,\n",
    "        train_dataset = dataset,\n",
    "        eval_dataset = eval_dataset, # Can set up evaluation!\n",
    "        args = training_args,\n",
    "        data_collator = collator,\n",
    "    )\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88895407-4f2f-4bd4-9d67-9edc44ce417b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "try:\n",
    "    del model\n",
    "    del tokenizer\n",
    "except:\n",
    "    pass\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39597fc1-42ae-4ca4-85da-4d9a8d8ee935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.8.1: Fast Qwen2 patching. Transformers: 4.55.0. vLLM: 0.10.0.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-80GB. Num GPUs = 1. Max memory: 79.254 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.05it/s]\n",
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.1.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2025.8.1 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# model, tokenizer = get_model_and_tokenizer(max_seq_length=8192)\n",
    "# model, tokenizer = get_model_and_tokenizer(model_name=\"Qwen/Qwen2.5-14B-Instruct\")\n",
    "model, tokenizer = get_model_and_tokenizer(model_name=\"Qwen/Qwen2.5-7B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91be8bfb-88d8-4996-80e1-cbcd3694acf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 583/583 [00:00<00:00, 3992.62 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare HF datasets\n",
    "def merge_prompt_completion(example):\n",
    "    # Make sure your completion already ends with EOS\n",
    "    return {\"text\": example[\"prompt\"] + example[\"completion\"]}\n",
    "\n",
    "try:\n",
    "    hf_ds = dataset.map(\n",
    "    merge_prompt_completion,\n",
    "    remove_columns=[c for c in dataset[\"train\"].column_names if c not in (\"text\",)],\n",
    "    )\n",
    "except:\n",
    "    hf_ds = dataset.map(\n",
    "        merge_prompt_completion,\n",
    "        remove_columns=[c for c in dataset.column_names if c not in (\"text\",)],\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "collator = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1bbea1c-0d3e-4b2a-ad85-499be490dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check how many samples are truncated.\n",
    "# i = 0\n",
    "# lost_tokens = 0\n",
    "# total_tokens = 0\n",
    "# for text in hf_ds[\"text\"]:\n",
    "#     tokens = tokenizer.encode(text)\n",
    "#     total_tokens += len(tokens)\n",
    "#     if len(tokens) > 1024:\n",
    "#         i += 1\n",
    "#         lost_tokens += len(tokens)-1024\n",
    "# print(f\"Number of samples truncated: ({i/len(hf_ds)*100:.2f}%) {i}/{len(hf_ds)}\")\n",
    "# print(f\"Total tokens truncated: ({lost_tokens/total_tokens*100:.2f}%) {lost_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27582426-dad6-4a72-b2ce-3755a849c274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================\\TRAINING SFT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=2): 100%|██████████| 707/707 [00:01<00:00, 598.86 examples/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n================\\TRAINING SFT\")\n",
    "\n",
    "try:\n",
    "    sft_trainer = get_sft_trainer(model, tokenizer, hf_ds[\"train\"], eval_dataset=hf_ds[\"test\"], training_steps=15, collator=collator)\n",
    "except:\n",
    "    sft_trainer = get_sft_trainer(model, tokenizer, hf_ds, training_steps=15, collator=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08206a2a-a326-47d9-9f45-50026c6da4c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 707 | Num Epochs = 1 | Total steps = 89\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 161,480,704 of 7,777,097,216 (2.08% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='89' max='89' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [89/89 03:21, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.406900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.359100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.163400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.776700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.681500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.659300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.595800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.457900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.328800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.255300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.289700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.251200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.281300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.297600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.275600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.258700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.291800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.248300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.200200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.221600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.226200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.234500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.212200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.269800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.218100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.195300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.209200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.259200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.201900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.199100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.203900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.186600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.172700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.191100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.199900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.199200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.155500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.226400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.167900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.169800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.197200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.178100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.176300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.168500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.163300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.167900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.186800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.166700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.190400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.156800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.195700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.164100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.174800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.170200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.169300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.172600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.158100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.176100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.171500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.174400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.171800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.152600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.156600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.147400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.149500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.153600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.151200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.162900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.166200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.136500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.178500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.160100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.177200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.202700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.154300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.203200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.164700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.156000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.176500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.153500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.166200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.180200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.168700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.154400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.175500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "sft_trainer.train()\n",
    "print(\"\\n\\n\\n\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "370de55e-efb2-4a45-8f8e-a27722cda05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wherever you want to save:\n",
    "\n",
    "# out_dir = \"models/14B_rag_20handpicked_lorareg\" \n",
    "# out_dir = \"models/14B_rag_all_lorareg\" \n",
    "# out_dir = \"models/14B_rag_all_lorareg_lowlr\" \n",
    "\n",
    "# out_dir = \"models/7B_vanilla_all\" \n",
    "# out_dir = \"models/7B_vanilla_20handpicked\"\n",
    "\n",
    "# out_dir = \"models/7B_rag_all\"\n",
    "# out_dir = \"models/7B_rag_20handpicked\"\n",
    "\n",
    "# out_dir = \"models/14B_react_vanilla_all\" \n",
    "# out_dir = \"models/14B_react_rag_all\" \n",
    "# out_dir = \"models/14B_react_vanilla_20handpicked\" \n",
    "\n",
    "# out_dir = \"models/14B_state_rag_selfgenerated\" \n",
    "# out_dir = \"models/14B_react_rag_selfgenerated\" \n",
    "\n",
    "# out_dir = \"models/7B_state_rag_selfgenerated\" \n",
    "out_dir = \"models/7B_react_rag_selfgenerated\" \n",
    "\n",
    "# write model + tokenizer\n",
    "model.save_pretrained(out_dir)\n",
    "tokenizer.save_pretrained(out_dir)\n",
    "sft_trainer.save_model(out_dir)               # saves model, config, trainer state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (finetune)",
   "language": "python",
   "name": "finetune"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
